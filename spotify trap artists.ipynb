{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Merge \n",
    "### Playing with the Spotify API\n",
    "Using Spotipy wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import spotipy\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "import numpy.random as rand\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "define the API connection - usually log in from here as well...\n",
    "'''\n",
    "token = util.prompt_for_user_token(' ', '')\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uri(artist):\n",
    "    results = sp.search(q = \"artist:\" + artist, type = \"artist\")\n",
    "    artist_id = results['artists']['items'][0]['uri'] # changed from '1' to '0' ??\n",
    "   \n",
    "    return(artist_id)\n",
    "\n",
    "def related_artists(name):\n",
    "    related = sp.artist_related_artists(get_uri(name))\n",
    "    rels = []\n",
    "    for artist in related['artists']:\n",
    "        rels.append(artist['name'])\n",
    "    return(rels)\n",
    "\n",
    "\n",
    "def next_artist(artist, artists = []):\n",
    "    ''' artists is the storage of past people that have been in there'''\n",
    "    RelatedArtists = related_artists(artist)\n",
    "    relates = [] # empty list to append with future \n",
    "    \n",
    "    for i in RelatedArtists:\n",
    "        relates.append(related_artists(i) )\n",
    "    \n",
    "    # create a bag of words - to index each artist in:\n",
    "    \n",
    "    BOW = np.unique(relates).flatten() \n",
    "    vecs = np.zeros((len(relates), len(BOW)))  # unique artists as columns...\n",
    "\n",
    "    for i in range(len(relates)):\n",
    "        # turn each into a vector of 0 and 1\n",
    "        for art in relates[i]:\n",
    "            # this loops over each artist:\n",
    "            idx = np.where(BOW == art)[0][0]\n",
    "            # set that idx number = to 1\n",
    "            vecs[i,idx] = 1\n",
    "    \n",
    "    # then calculate cosine similarity and select the lowest similarity artist and print them\n",
    "    sims = np.zeros((len(relates),len(relates)))\n",
    "    sim_means = []\n",
    "    for i in range(len(vecs)):\n",
    "        # loop over each vector\n",
    "        for j in range(len(vecs)):\n",
    "            # do this again because you want to get similarity between each matrix...\n",
    "            sims[i,j] = 1 - spatial.distance.cosine(vecs[i],vecs[j])\n",
    "        # calculate row wise means:\n",
    "        sim_means.append(np.var(sims[i] ))\n",
    "    \n",
    "    # find the lowest scoring similarity artist\n",
    "    lowest_idx = np.where(sim_means == max(sim_means) )[0][0]      \n",
    "    return(RelatedArtists[lowest_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create function to find x closest artists from their autoencodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = pd.read_csv('401.csv').ix[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def artist_path(start_art, target_art, steps):\n",
    "    \n",
    "    step_size = 1/steps\n",
    "    artists = []\n",
    "    artists.append(start_art)\n",
    "    \n",
    "    # need some try - in case the artist name is not valid...\n",
    "    a1_idx = np.where(enc['Artist'] == start_art)[0][0]\n",
    "    a2_idx = np.where(enc['Artist'] == target_art)[0][0]\n",
    "    \n",
    "    # line equation form:\n",
    "    # line = np.array(enc.ix[a1_idx,:3]) + t * (np.array(enc.ix[a2_idx,:3] - np.array(enc.ix[a1_idx,:3])) # for some t\n",
    "    \n",
    "    for i in range(1,steps+1):\n",
    "        # 1 -> steps because already dealth with the first point...\n",
    "        # calculate the target point on line\n",
    "        point = np.array(enc.ix[a1_idx,:3]) + i*step_size * (np.array(enc.ix[a2_idx,:3] - np.array(enc.ix[a1_idx,:3])) )  \n",
    "        # find closest point by calculating distances of all artists...\n",
    "        distances = []\n",
    "                                                             \n",
    "                                                            \n",
    "        for j in range(len(enc)):\n",
    "            distances.append( spatial.distance.euclidean(enc.ix[j,:3], point) )\n",
    "        # choose minimum distance vector:\n",
    "        choice_idx = np.where(distances == np.min(distances) )[0][0]\n",
    "        \n",
    "        artists.append(enc['Artist'][choice_idx])\n",
    "    return(artists)                                                     \n",
    "                                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drake', 'X Ambassadors', 'Disclosure', 'Calvin Harris']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_path('Drake','Calvin Harris', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in songs for an artist:\n",
    "Start with just the top tracks for an artist and an audio analysis...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_track(artURI, last_track):   \n",
    "    trackids = [] \n",
    "    K = sp.artist_top_tracks(artURI)\n",
    "    for i in range(10):\n",
    "        trackids.append(K['tracks'][i]['uri'])\n",
    "    \n",
    "    # then do audio analysis to find the best one:\n",
    "    features = np.zeros((len(trackids),13)) # for storing song features in a grid...\n",
    "    for track in range(len(trackids)):\n",
    "        Track = sp.audio_features(trackids[track])\n",
    "        # features\n",
    "        feats = ['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveliness',\\\n",
    "                 'loudness','mode','speechiness','tempo','time_signature','valence']\n",
    "        for i in range(len(feats)):\n",
    "        features[track, i] = Track[track][feats[i]]   \n",
    "    # next calculate similarity between all tracks...\n",
    "    return(trackids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acousticness': 0.168,\n",
       "  'analysis_url': 'https://api.spotify.com/v1/audio-analysis/7MXVkk9YMctZqd1Srtv4MB',\n",
       "  'danceability': 0.675,\n",
       "  'duration_ms': 230453,\n",
       "  'energy': 0.595,\n",
       "  'id': '7MXVkk9YMctZqd1Srtv4MB',\n",
       "  'instrumentalness': 3.36e-06,\n",
       "  'key': 7,\n",
       "  'liveness': 0.136,\n",
       "  'loudness': -7.033,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.284,\n",
       "  'tempo': 185.998,\n",
       "  'time_signature': 4,\n",
       "  'track_href': 'https://api.spotify.com/v1/tracks/7MXVkk9YMctZqd1Srtv4MB',\n",
       "  'type': 'audio_features',\n",
       "  'uri': 'spotify:track:7MXVkk9YMctZqd1Srtv4MB',\n",
       "  'valence': 0.49}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.audio_features('spotify:track:7MXVkk9YMctZqd1Srtv4MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Larger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('genres.csv').ix[:,1].tolist()\n",
    "artists = pd.read_csv('artists.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# setup null matrix length of artists by length of genres...\n",
    "GEN = np.zeros((len(artists),len(genres)))\n",
    "\n",
    "# run a loop over each artist to get their vector of \n",
    "uris = artists['URI']\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(uris)):\n",
    "    if (i % 100) == 0 :\n",
    "        print(i)\n",
    "        print('Time passed so far is: ', time.time() - start_time)\n",
    "        print('-----------------------------------------')\n",
    "    K = sp.artist(uris[i])['genres']\n",
    "    for k in range(len(K)):\n",
    "        idx = np.where(np.array(genres) == K[k])[0][0]\n",
    "        GEN[i,idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a csv file of artists and their genre matrix:\n",
    "GEN2 = pd.DataFrame(GEN)\n",
    "vecs = pd.concat([artists,GEN2],axis=1).ix[:,3:]\n",
    "\n",
    "# normalize then autoencode this...\n",
    "vecs['popularity'] = vecs['popularity']/100\n",
    "vecs['followers'] = vecs['followers'] / 10000000 \n",
    "\n",
    "vecs.to_csv('Genre_matrix')\n",
    "\n",
    "inps = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## From 20k now import as  vecs:\n",
    "vecs = pd.read_csv('raw_data.csv',encoding = \"ISO-8859-1\")\n",
    "namezz = []\n",
    "genres = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(80):\n",
    "    print('next 50...')\n",
    "    \n",
    "    LIST = sp.artists(URIs.tolist()[50*i:50*(i+1)] ) ['artists']\n",
    "    for j in range(50):\n",
    "        namezz.append(LIST[j]['name'])\n",
    "        genres.append(LIST[j]['genres'])\n",
    "        \n",
    "    print('Time passed so far is: ', time.time() - start_time)\n",
    "    print('-----------------------------------------')  \n",
    "    \n",
    "# create genre vectors:\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "genrez = np.sort(np.unique(flatten(genres)) )\n",
    "\n",
    "### Get genre matrix for each person...\n",
    "# setup null matrix length of artists by length of genres...\n",
    "GEN = np.zeros((len(namezz),len(genrez)))\n",
    "\n",
    "for i in range(len(uris)):\n",
    "    if i <4000:\n",
    "        G = genres[i]        \n",
    "        for k in range(len(G)):\n",
    "            idx = np.where(genrez == G[k])[0][0]\n",
    "            GEN[i,idx] = 1\n",
    "inps = GEN # rename for ez use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' make the autoencoder'''\n",
    "inputs = Input(shape=(np.shape(inps)[1],))\n",
    "fl_dim = 50\n",
    "encoding_dim = 3\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "ENCOD1 = Dense(fl_dim, activation='relu')(inputs)\n",
    "ENCOD2 = Dense(encoding_dim, activation='relu')(ENCOD1)\n",
    "DECOD1 = Dense(fl_dim, activation='relu')(ENCOD2)\n",
    "DECOD2 = Dense(np.shape(inps)[1], activation='linear')(DECOD1)\n",
    "#predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "autoencoder = Model(input=inputs, output=DECOD2)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(inputs, output = ENCOD2)\n",
    "\n",
    "# create a placeholder for an encoded (N-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last slayer of the autoencoder model\n",
    "#decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "#decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "### compile the model...\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(inps, inps,\n",
    "                nb_epoch=10,batch_size=10,shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' save the predictions... '''\n",
    "encoded_inputs = pd.DataFrame(encoder.predict(inps))\n",
    "\n",
    "''' add in names and spotify URIs to the df above... '''\n",
    "encoded_inputs['Artist'] = namezz\n",
    "encoded_inputs.to_csv('MORE_encoded_artists.csv')\n",
    "enc = encoded_inputs\n",
    "enc['URI'] = URIs[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def artist_path(start_art, target_art, steps):\n",
    "    \n",
    "    step_size = 1/steps\n",
    "    artists = []\n",
    "    artists.append([start_art,start_art,start_art,start_art,start_art])\n",
    "    uri = []\n",
    "    uri.append([enc.loc[enc['Artist']== start_art]['URI'].reset_index(drop=True)[0],\\\n",
    "                enc.loc[enc['Artist']== start_art]['URI'].reset_index(drop=True)[0],\\\n",
    "                enc.loc[enc['Artist']== start_art]['URI'].reset_index(drop=True)[0],\\\n",
    "                enc.loc[enc['Artist']== start_art]['URI'].reset_index(drop=True)[0],\\\n",
    "                enc.loc[enc['Artist']== start_art]['URI'].reset_index(drop=True)[0]])\n",
    "    \n",
    "    # need some try - in case the artist name is not valid...\n",
    "    a1_idx = np.where(np.array(enc['Artist']) == str(start_art))[0][0]\n",
    "    a2_idx = np.where(np.array(enc['Artist']) == str(target_art))[0][0]\n",
    "    \n",
    "    # line equation form:\n",
    "    # line = np.array(enc.ix[a1_idx,:3]) + t * (np.array(enc.ix[a2_idx,:3] - np.array(enc.ix[a1_idx,:3])) # for some t\n",
    "    \n",
    "    for i in range(1,steps+1):\n",
    "        # 1 -> steps because already dealth with the first point...\n",
    "        # calculate the target point on line\n",
    "        point = np.array(enc.ix[a1_idx,:3]) + i*step_size * (np.array(enc.ix[a2_idx,:3] - np.array(enc.ix[a1_idx,:3])) )  \n",
    "        # find closest point by calculating distances of all artists..\n",
    "        \n",
    "        distances = []\n",
    "                                                             \n",
    "        # first we can discard artists who have a higher than absolute x% variation on all three metrics\n",
    "        # this is to speed up the algorithm\n",
    "        #percen = .5\n",
    "        \n",
    "        #enc2 = enc[(enc[0]>point[0]*(1-percen)) & (enc[0]<point[0]*(1+percen))]\n",
    "        \n",
    "        for j in range(len(enc)):\n",
    "            distances.append( spatial.distance.euclidean(enc.ix[j,:3], point) ) # can also try euclidean dist...\n",
    "        # choose minimum 3 distance vector:\n",
    "        choice_idx = []\n",
    "        \n",
    "        ord_dist = np.sort(distances)\n",
    "        first = ord_dist[0]\n",
    "        second = ord_dist[1]\n",
    "        third = ord_dist[2]\n",
    "        fourth = ord_dist[3]\n",
    "        fifth = ord_dist[4]\n",
    "        \n",
    "        choice_idx.append(np.where(distances == first )[0][0])\n",
    "        choice_idx.append(np.where(distances == second )[0][0])\n",
    "        choice_idx.append(np.where(distances == third )[0][0])\n",
    "        choice_idx.append(np.where(distances == fourth )[0][0])\n",
    "        choice_idx.append(np.where(distances == fifth )[0][0])\n",
    "        \n",
    "        print(choice_idx)\n",
    "        artists.append(enc['Artist'][choice_idx].tolist())\n",
    "        uri.append(enc['URI'][choice_idx].tolist())\n",
    "    return(artists, uri)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spotify:artist:1tqZaCwM57UFKjWoYwMLrw',\n",
       " 'spotify:artist:6BMhCQJYHxxKAeqYS1p5rY',\n",
       " 'spotify:artist:1UdQqCUR7RwB9YYJONwbdM']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc['URI'][[963, 3191, 762]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2176, 429, 491, 491, 2485]\n",
      "[3594, 3853, 3313, 2741, 3168]\n",
      "[1427, 405, 535, 2786, 2308]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['Alesso', 'Alesso', 'Alesso'],\n",
       "  ['Luke James', 'Kwabs', 'Stacy Barthe', 'Stacy Barthe', 'Tank'],\n",
       "  ['Beyoncé',\n",
       "   \"Colby O'Donis\",\n",
       "   'Amy Winehouse',\n",
       "   'Kanye West',\n",
       "   'Far East Movement'],\n",
       "  ['Tory Lanez', 'Greg Brown', 'A$AP Rocky', 'Lifehouse', 'R. City']],\n",
       " [['spotify:artist:4AVFqumd2ogHFlRbKIjp1t',\n",
       "   'spotify:artist:4AVFqumd2ogHFlRbKIjp1t',\n",
       "   'spotify:artist:4AVFqumd2ogHFlRbKIjp1t'],\n",
       "  ['spotify:artist:4E7AV8mtElSjHZP3xA9kyU',\n",
       "   'spotify:artist:0r0KdmVS1Er3kaFnl1KPog',\n",
       "   'spotify:artist:0yq6uHIfFks9yOURUuCITV',\n",
       "   'spotify:artist:0yq6uHIfFks9yOURUuCITV',\n",
       "   'spotify:artist:4mwXUEKaW4ftbncf9Hi58l'],\n",
       "  ['spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
       "   'spotify:artist:7fObcBw9VM3x7ntWKCYl0z',\n",
       "   'spotify:artist:6Q192DXotxtaysaqNPy5yR',\n",
       "   'spotify:artist:5K4W6rqBFWDnAN6FQUkS6x',\n",
       "   'spotify:artist:698hF4vcwHwPy8ltmXermq'],\n",
       "  ['spotify:artist:2jku7tDXc6XoB6MO2hFuqg',\n",
       "   'spotify:artist:0nnDCl6emTFoWtygqSs4Jy',\n",
       "   'spotify:artist:13ubrt8QOOCPljQ2FL1Kca',\n",
       "   'spotify:artist:5PokPZn11xzZXyXSfnvIM3',\n",
       "   'spotify:artist:4TH4BHy0LdBi3dpBW4P2UX']])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_path('Alesso','Tory Lanez', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_track(artURI, last_track):   \n",
    "    trackids = [] \n",
    "    K = sp.artist_top_tracks(artURI)['tracks']\n",
    "    for i in range(len(K)):\n",
    "        trackids.append(K[i]['uri'])\n",
    "    \n",
    "    # then do audio analysis to find the best one:\n",
    "    features = np.zeros((len(trackids),13)) # for storing song features in a grid...\n",
    "    Track = sp.audio_features(trackids)\n",
    "    for track in range(len(trackids)):\n",
    "        feats = ['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveliness',\\\n",
    "                 'loudness','mode','speechiness','tempo','time_signature','valence']\n",
    "        for i in range(len(feats)):\n",
    "        features[track, i] = Track[track][feats[i]] \n",
    "        \n",
    "    # next calculate similarity between all tracks...\n",
    "    ''' for each track calculate similarity between last track '''\n",
    "    ################################\n",
    "    # get last track features:\n",
    "    Track = sp.audio_features(last_track)\n",
    "    last_trk_feat = []\n",
    "    last_trk_feat.append(Track[0]['acousticness'])\n",
    "    last_trk_feat.append(Track[0]['danceability'])\n",
    "    last_trk_feat.append(Track[0]['duration_ms'])\n",
    "    last_trk_feat.append(Track[0]['energy'])\n",
    "    last_trk_feat.append(Track[0]['instrumentalness'])\n",
    "    last_trk_feat.append(Track[0]['key'])\n",
    "    last_trk_feat.append(Track[0]['liveness'])\n",
    "    last_trk_feat.append(Track[0]['loudness'])\n",
    "    last_trk_feat.append(Track[0]['mode'])\n",
    "    last_trk_feat.append(Track[0]['speechiness'])\n",
    "    last_trk_feat.append(Track[0]['tempo'])\n",
    "    last_trk_feat.append(Track[0]['time_signature'])\n",
    "    last_trk_feat.append(Track[0]['valence'])\n",
    "     ##########################3\n",
    "        \n",
    "    similarity = []\n",
    "    for i in range(len(features)):\n",
    "        # cosine sim between last track vector and each track features...\n",
    "        similarity.append(spatial.distance.euclidean( features[i] , last_trk_feat  ) ) # try euclidean distance\n",
    "        \n",
    "    if np.min(similarity) == 0:\n",
    "        # find maximum similarity track ID\n",
    "        print('second =: ', sorted(similarity)[1])\n",
    "        second = sorted(similarity)[1] #[len(similarity)-2] # second SMALLEST number\n",
    "    \n",
    "        # then we have the same song...\n",
    "        idx = np.where(similarity == second)[0][0]\n",
    "        print('index = ',idx)\n",
    "    \n",
    "    else:\n",
    "        idx = np.where(similarity == np.min(similarity) )[0][0]\n",
    "        print('index =', idx)\n",
    "    \n",
    "    #then use the index to get which track:\n",
    "    track_name = sp.track(trackids[idx])['name']\n",
    "    \n",
    "    return(track_name,trackids[idx], similarity[idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_first_track(art1, art2):   \n",
    "    trackids1 = [] \n",
    "    trackids2 = [] \n",
    "    K = sp.artist_top_tracks(art1)\n",
    "    for i in range(5):\n",
    "        trackids1.append(K['tracks'][i]['uri'])\n",
    "        \n",
    "    J = sp.artist_top_tracks(art2)\n",
    "    for i in range(5):\n",
    "        trackids2.append(J['tracks'][i]['uri'])\n",
    "    \n",
    "    # then do audio analysis to find the best one:\n",
    "    features1 = np.zeros((len(trackids1),13)) # for storing song features in a grid...\n",
    "    Track1 = sp.audio_features(trackids1)\n",
    "    for track in range(len(trackids1)):\n",
    "        feats = ['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveliness',\\\n",
    "                 'loudness','mode','speechiness','tempo','time_signature','valence']\n",
    "        for i in range(len(feats)):\n",
    "        features[track, i] = Track[track][feats[i]] \n",
    "\n",
    "    features2 = np.zeros((len(trackids2),13)) # for storing song features in a grid...\n",
    "    Track2 = sp.audio_features(trackids2)\n",
    "    for track in range(len(trackids2)):\n",
    "        feats = ['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveliness',\\\n",
    "                 'loudness','mode','speechiness','tempo','time_signature','valence']\n",
    "        for i in range(len(feats)):\n",
    "        features2[track, i] = Track[track][feats[i]] \n",
    "        \n",
    "    similarity = []\n",
    "    for i in range(len(features)):\n",
    "        # cosine sim between last track vector and each track features...\n",
    "        \n",
    "        similarity.append(1 - spatial.distance.cosine( features[i] , last_trk_feat  ) )\n",
    "    \n",
    "    # find maximum similarity track ID\n",
    "    second = sorted(similarity)[len(similarity)-2] # second largest nubmer\n",
    "    \n",
    "    if np.max(similarity) > 0.999999999:\n",
    "        # then we have the same song...\n",
    "        idx = np.where(similarity == second)[0][0]\n",
    "    \n",
    "    else:\n",
    "        idx = np.where(similarity == np.max(similarity) )[0][0]\n",
    "    \n",
    "    #then use the index to get which track:\n",
    "    track_name = sp.track(trackids[idx])['name']\n",
    "    \n",
    "    return(track_name,trackids[idx], similarity[idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start with an artist and a target artist - get their path and the steps... then iteratively get the next track...\n",
    "# get a random first track though of artist 1\n",
    "\n",
    "def music_merge(a1, a2, steps):\n",
    "    \n",
    "    # get artist path:\n",
    "    namez , uriz = artist_path(a1,a2, steps)\n",
    "    \n",
    "    tracks = []\n",
    "    track_names = []\n",
    "    \n",
    "    # for the first artist randomly choose first track:\n",
    "    rand_ix = rand.randint(0,3) # from top 10 tracks\n",
    "    \n",
    "    # need to find the top x of their traks (some less than 5)\n",
    "    \n",
    "    first_track = sp.artist_top_tracks(uriz[0][0])['tracks'][rand_ix]['uri']\n",
    "    first_track_name = sp.artist_top_tracks(uriz[0][0])['tracks'][rand_ix]['name']\n",
    "    tracks.append(first_track)\n",
    "    track_names.append(first_track_name)\n",
    "    \n",
    "    art_choice = 0 # initialize it\n",
    "    \n",
    "    for i in range(1,steps+1):\n",
    "        print(i)\n",
    "        # get next track...\n",
    "        \n",
    "        # 5 candidates artists per track:\n",
    "        \n",
    "        cand_name = []\n",
    "        cand_ID = []\n",
    "        cand_sim = []\n",
    "        \n",
    "        if( i != steps):\n",
    "            for a in range(len(namez[0])):\n",
    "                next_track_name, next_trackID, next_track_sim = get_next_track( uriz[i][a],tracks[i-1])\n",
    "                cand_name.append(next_track_name)\n",
    "                cand_ID.append(next_trackID)\n",
    "                cand_sim.append(next_track_sim)\n",
    "            print(cand_sim)    \n",
    "            best_track_idx = np.where(cand_sim == np.min(cand_sim))[0]\n",
    "            if len(best_track_idx)>1:\n",
    "                print('best track is tied -- choosing the first track')\n",
    "                best_track_idx = best_track_idx[0]\n",
    "            print(best_track_idx)\n",
    "        # pick which artist:\n",
    "            art_choice = best_track_idx\n",
    "        \n",
    "            tracks.append(cand_ID[best_track_idx])\n",
    "            track_names.append(cand_name[best_track_idx])\n",
    "        else:\n",
    "            # last iteration:\n",
    "            next_track_name, next_trackID, next_track_sim = get_next_track( uriz[i][0],tracks[i-1])\n",
    "            tracks.append(next_trackID)\n",
    "            track_names.append(next_track_name)\n",
    "            \n",
    "    return(tracks, track_names,namez)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[985, 1512, 1512, 138, 1732]\n",
      "[1379, 3662, 2375, 888, 259]\n",
      "[1736, 3941, 1586, 2941, 2293]\n",
      "[1125, 1108, 3179, 3731, 858]\n",
      "[2979, 1108, 3493, 3579, 3579]\n",
      "[3493, 3434, 3579, 3579, 2979]\n",
      "1\n",
      "index = 1\n",
      "index = 6\n",
      "index = 6\n",
      "index = 5\n",
      "index = 2\n",
      "[10653.010097454642, 17266.007677270423, 17266.007677270423, 8266.126384294823, 5199.0133309283165]\n",
      "[4]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:49: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/home/max/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:50: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 7\n",
      "index = 0\n",
      "index = 6\n",
      "index = 0\n",
      "index = 8\n",
      "[2904.2593898678024, 11906.056428148822, 3187.0057284594795, 819.0110346785652, 3613.388999909364]\n",
      "[3]\n",
      "3\n",
      "index = 7\n",
      "index = 4\n",
      "index = 8\n",
      "index = 6\n",
      "index = 4\n",
      "[18248.000729148913, 2328.3290904928494, 4941.0213942407745, 8355.001343239488, 1101.7357881276523]\n",
      "[4]\n",
      "4\n",
      "index = 2\n",
      "index = 8\n",
      "index = 3\n",
      "index = 9\n",
      "index = 7\n",
      "[6464.065334091579, 18438.031081416513, 2092.0220741148623, 11799.097962678514, 3345.1741120640736]\n",
      "[2]\n",
      "5\n",
      "index = 5\n",
      "index = 8\n",
      "index = 8\n",
      "index = 4\n",
      "index = 4\n",
      "[4067.4241784840433, 16346.04529308138, 10573.1902046574, 3627.5655958431757, 3627.5655958431757]\n",
      "best track is tied -- choosing the first track\n",
      "3\n",
      "6\n",
      "index = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['spotify:track:3t7aNy8nHeWkaY4SAncR7n',\n",
       "  'spotify:track:7cKQE2K6ggLByzlIMtCxzu',\n",
       "  'spotify:track:1IWv7yYMFplrKaZDUldFJn',\n",
       "  'spotify:track:2f9h72MZuU0ZdEnGIfGf5H',\n",
       "  'spotify:track:2J3n32GeLmMjwuAzyhcSNe',\n",
       "  'spotify:track:4wNFFRLo7EnEdbf2eoFLEU',\n",
       "  'spotify:track:4yEvfGgJ9tYfyfXXMLza1V'],\n",
       " ['A Time for Us',\n",
       "  'Bottled Up Tight',\n",
       "  \"Wasn't Expecting That\",\n",
       "  'Here We Go',\n",
       "  'Say It, Just Say It',\n",
       "  'Reasons To Love You',\n",
       "  'She Used to Love Me a Lot'],\n",
       " [['Joe Pass', 'Joe Pass', 'Joe Pass', 'Joe Pass', 'Joe Pass'],\n",
       "  ['Wisin & Yandel',\n",
       "   'Lucky Luciano',\n",
       "   'Lucky Luciano',\n",
       "   'Starsailor',\n",
       "   'Luke Sital-Singh'],\n",
       "  ['Staysman & Lazz', 'Tom Zanetti', 'Foy Vance', 'Jamie Lawson', 'Roo Panes'],\n",
       "  ['Joe Purdy',\n",
       "   'Wrabel',\n",
       "   'Noah Gundersen',\n",
       "   'Pete Yorn',\n",
       "   'Drew Holcomb & The Neighbors'],\n",
       "  ['Corinne Bailey Rae',\n",
       "   'Lane 8',\n",
       "   \"The Mowgli's\",\n",
       "   'Benjamin Francis Leftwich',\n",
       "   'Matt Simons'],\n",
       "  ['Priscilla Ahn', 'Lane 8', 'Johnny Cash', 'Meiko', 'Meiko'],\n",
       "  ['Johnny Cash', 'The Highwaymen', 'Meiko', 'Meiko', 'Priscilla Ahn']])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_merge('Joe Pass','Johnny Cash',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
